{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "entries = []\n",
    "entry = []\n",
    "urlnumber = 2\n",
    "while urlnumber < 105: \n",
    "    url = 'https://forums.edmunds.com/discussion/7526/general/x/midsize-sedans-2-0/p%d' % (urlnumber,)\n",
    "    try:\n",
    "        r = requests.get(url, timeout = 10) \n",
    "    except Exception as e:\n",
    "        print(\"Error message:\",e)\n",
    "        break;\n",
    "\n",
    "    data = r.text\n",
    "    \n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    \n",
    "    for div in soup.find_all('div'):\n",
    "        entry = []\n",
    "        if(div.get('class') != None and div.get('class')[0] == 'Comment'): \n",
    "            ps = div.find_all('p') \n",
    "            aas = div.find_all('a')\n",
    "            spans = div.find_all('span')\n",
    "            times = div.find_all('time') \n",
    "            concat_str = ''\n",
    "            for str in aas[1].contents: \n",
    "                if str != \"<br>\" or str != \"<br/>\": \n",
    "                    concat_str = (concat_str + ' '+ str).encode(\"utf-8\").strip()\n",
    "            entry.append(concat_str)\n",
    "\n",
    "            concat_str = ''\n",
    "            for str in times[0].contents:\n",
    "                if str != \"<br>\" or str != \"<br/>\":\n",
    "                    concat_str = (concat_str + ' '+ str).encode('iso-8859-1').strip()\n",
    "            entry.append(concat_str)\n",
    "\n",
    "            for div in div.find_all('div'):\n",
    "                if (div.get('class') != None and div.get('class')[0] == 'Message'): \n",
    "                    blockquotes = []\n",
    "                    x = div.get_text()\n",
    "                    for bl in div.find_all('blockquote'):\n",
    "                        blockquotes.append(bl.get_text()) \n",
    "                        bl.decompose()\n",
    "                    ascii_encoding = div.get_text().replace(\"\\n\",\" \").replace(\"<br/>\",\"\").encode('ascii','replace')\n",
    "                    latin1_encoding = ascii_encoding.decode('ascii').encode('iso-8859-1')\n",
    "                    entry.append(latin1_encoding)\n",
    "\n",
    "                    for bl in blockquotes:\n",
    "                        ascii_encoding = bl.replace(\"\\n\",\" \").replace(\"<br/>\",\"\").encode('ascii','replace')\n",
    "                        latin1_encoding = ascii_encoding.decode('ascii').encode('iso-8859-1')\n",
    "                        entry.append(latin1_encoding)\n",
    "\n",
    "            entries.append(entry)\n",
    "            \n",
    "    urlnumber += 1\n",
    "\n",
    "stringlist=[[x.decode('iso-8859-1') for x in entry] for entry in entries]\n",
    "with open('edmunds_extraction.csv', 'w') as output:\n",
    "    writer = csv.writer(output, quoting=csv.QUOTE_ALL)\n",
    "    writer.writerows(stringlist)\n",
    "\n",
    "print (\"Wrote to edmunds_extraction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('edmunds_extraction.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['userid','date','message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brands and models from external source plus models.csv file given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brands=pd.read_csv('brands.csv')\n",
    "df_models=pd.read_csv('model.csv')\n",
    "df_brand_model=pd.merge(df_models,df_brands,left_on='brand_id',right_on='id')\n",
    "df_brand_model=df_brand_model[['name_x','name_y']].rename(columns={'name_x':'Model','name_y':'Brand'})\n",
    "df_brand_model_given=pd.read_csv('models.csv',header=None).rename(columns={0:'Brand',1:'Model'})\n",
    "df_brand_model['Model']=df_brand_model['Model'].apply(lambda x:x.lower())\n",
    "df_brand_model['Brand']=df_brand_model['Brand'].apply(lambda x:x.lower())\n",
    "df_brand_model_given['Model']=df_brand_model_given['Model'].apply(lambda x:x.lower())\n",
    "df_brand_model_given['Brand']=df_brand_model_given['Brand'].apply(lambda x:x.lower())\n",
    "df_brand_model_final=df_brand_model_given.append(df_brand_model).drop_duplicates()\n",
    "df_brand_model=df_brand_model_final.reset_index().drop(columns='index')\n",
    "df_brand_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message']=df['message'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df[1:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['message'] = df['message'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "df['message']=df['message'].apply(lambda x:word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging words with pos_tag and lemmatization\n",
    "- Extracted only the nouns from pos tag as brands and models will come under them\n",
    "- Didn't use porter stemmer as it can manipulate the brand names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "df['message']=df['message'].apply(lambda x:nltk.pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(len(df['message'])):\n",
    "    df['message'].iloc[l]=[j[0] for j in df['message'].iloc[l] if j[1].startswith(\"NN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w).lower() for w in text]\n",
    "df['message']=df['message'].apply(lambda x:lemmatize_text(x))\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "def porter_stemmer(text):\n",
    "    return [ps.stem(w).lower() for w in text]\n",
    "#df['message'].apply(lambda x:porter_stemmer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brand_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['message'])):\n",
    "    for j in range(len(df_brand_model)):\n",
    "        if(df_brand_model['Model'].iloc[j] in df['message'].iloc[i]):\n",
    "            print(df_brand_model['Model'].iloc[j])\n",
    "            idx=df['message'].iloc[i].index(df_brand_model['Model'].iloc[j])\n",
    "            df['message'].iloc[i][idx]=df_brand_model['Brand'].iloc[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_brand_model['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brand_model['Brand']=df_brand_model['Brand'].str.replace(',','')\n",
    "df_brand_model['Model']=df_brand_model['Model'].str.replace('.','')\n",
    "df_brand_model['Brand']=df_brand_model['Brand'].str.replace('.','')\n",
    "df_brand_model['Model']=df_brand_model['Model'].str.replace(',','')\n",
    "df_brand_model['Brand']=df_brand_model['Brand'].apply(lambda x:x.strip())\n",
    "df_brand_model['Model']=df_brand_model['Model'].apply(lambda x:x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for brand in set(df_brand_model['Brand']):\n",
    "    df[brand]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for brand in set(df_brand_model['Brand']):\n",
    "    for j in range(len(df['message'])):\n",
    "        if(brand in df['message'].iloc[j]):\n",
    "            df[brand].iloc[j]=1\n",
    "        else:\n",
    "            df[brand].iloc[j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 3:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 brands by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_ten_brands=pd.DataFrame(df.iloc[:, 3:].sum(axis=0)).reset_index()\n",
    "df_top_ten_brands.columns=['brand','frequency']\n",
    "df_top_ten_brands=df_top_ten_brands.sort_values(by='frequency',ascending=False).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_top_ten_brands['brand'][2:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['sum']>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift Similarity of top 10 brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=df.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=df_1[['honda',\n",
    " 'ford',\n",
    " 'toyota',\n",
    " 'hyundai',\n",
    " 'nissan',\n",
    " 'mazda',\n",
    " 'sedan',\n",
    " 'problem',\n",
    " 'chevrolet',\n",
    " 'chrysler']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1=df_1.drop(columns=['sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1=df_1[df_1.columns[df_1.sum()>0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#len(df_1[(df_1[df_1.columns[0]]==1) & (df_1[df_1.columns[1]]==1)])/len(df_1[(df_1[df_1.columns[1]]==1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=df_1.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "for i in range(len(df_1.columns)):\n",
    "    for j in range(i+1,len(df_1.columns)):\n",
    "        #df_1[df_1.columns[i+1]].iloc[idx]=99\n",
    "        print(i,j,df_1.columns[i],df_1.columns[j],len(df_1[(df_1[df_1.columns[i]]==1) & (df_1[df_1.columns[j]]==1)])*len(df_1)/(len(df_1[(df_1[df_1.columns[i]]==1)])*len(df_1[(df_1[df_1.columns[j]]==1)])))\n",
    "        df_1[df_1.columns[j]].iloc[idx]=len(df_1[(df_1[df_1.columns[i]]==1) & (df_1[df_1.columns[j]]==1)])*len(df_1)/(len(df_1[(df_1[df_1.columns[i]]==1)])*len(df_1[(df_1[df_1.columns[j]]==1)]))\n",
    "    idx=idx+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=df_1[:len(df_1.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = df_1.shape\n",
    "df_1=pd.DataFrame(np.where(np.arange(m)[:,None] >= np.arange(n),np.nan,df_1))\n",
    "df_1=df_1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.index=cols\n",
    "df_1.columns=cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/Lift(dissimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=pd.DataFrame()\n",
    "for l in df_1.columns:\n",
    "    df_2[l]=np.nan\n",
    "    df_2[l]=df_1[l].astype('int')\n",
    "    df_2[l]=1/df_1[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
